# -*- coding: utf-8 -*-
"""arkeology.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cvu_jaG3m7vrCm2fQX8r34JE5U7wi4EP
"""

import cv2
import torch
import matplotlib.pyplot as plt
import numpy as np

# MiDaS modeli
midas = torch.hub.load("intel-isl/MiDaS", "DPT_Large")
midas.eval()

# Transform
transforms = torch.hub.load("intel-isl/MiDaS", "transforms")
transform = transforms.dpt_transform

# ğŸ“Œ BURADA DOSYA ADINI DEÄÄ°ÅTÄ°R
img = cv2.imread("antik3.jpg")
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

input_batch = transform(img).unsqueeze(0)

with torch.no_grad():
    depth = midas(input_batch)

depth = depth.squeeze().cpu().numpy()

# Normalize
depth_norm = cv2.normalize(depth, None, 0, 255, cv2.NORM_MINMAX)
depth_norm = depth_norm.astype(np.uint8)

# GÃ¶ster
plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.title("Orijinal GÃ¶rÃ¼ntÃ¼")
plt.imshow(img)
plt.axis("off")

plt.subplot(1,2,2)
plt.title("Derinlik HaritasÄ± (2D â†’ 3D)")
plt.imshow(depth_norm, cmap="inferno")
plt.axis("off")

plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt
import torch

# --- MiDaS Derinlik Tahmini BileÅŸenleri ---
print("MiDaS modelini yÃ¼klÃ¼yor...")
# MiDaS modeli (DPT_Large veya MiDaS_small tercih edilebilir)
# 'DPT_Large' daha iyi sonuÃ§lar verir ancak daha yavaÅŸtÄ±r.
# 'MiDaS_small' daha hÄ±zlÄ±dÄ±r ancak daha az hassastÄ±r.
midas = torch.hub.load("intel-isl/MiDaS", "DPT_Large")
midas.eval()

# MiDaS iÃ§in dÃ¶nÃ¼ÅŸÃ¼mler
transforms = torch.hub.load("intel-isl/MiDaS", "transforms")
# Model tipine gÃ¶re dÃ¶nÃ¼ÅŸÃ¼m seÃ§in
# EÄŸer DPT_Large kullanÄ±yorsanÄ±z dpt_transform, MiDaS_small kullanÄ±yorsanÄ±z small_transform
transform_midas = transforms.dpt_transform
print("MiDaS modeli yÃ¼klendi.\n")

# --- ArUco Ä°ÅŸaretleyici Poz Tahmini BileÅŸenleri ---
print("ArUco bileÅŸenlerini ayarlÄ±yor...")
aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)
parameters = cv2.aruco.DetectorParameters()
detector = cv2.aruco.ArucoDetector(aruco_dict, parameters)

# Marker gerÃ§ek dÃ¼nyadaki boyutu (metre cinsinden)
marker_length = 0.05  # 5 cm

# Kamera kalibrasyonu matrisi ve distorsiyon katsayÄ±larÄ±
# DoÄŸru 3B poz tahmini iÃ§in kameranÄ±zÄ± kalibre etmeniz ve gerÃ§ek deÄŸerleri buraya girmeniz GEREKÄ°R.
# AÅŸaÄŸÄ±daki deÄŸerler sadece bir yer tutucudur ve gerÃ§ek bir kalibrasyonu temsil etmez.
camera_matrix = np.array([[800, 0, 320],
                          [0, 800, 240],
                          [0,   0,   1]], dtype=float)
dist_coeffs = np.zeros((5,1))
print("ArUco bileÅŸenleri ayarlandÄ±.")

print("\nÅimdi hem derinlik tahmini hem de ArUco tespiti iÃ§in ortam hazÄ±rlandÄ±.")
print("Bir sonraki adÄ±mda, bir gÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kleyip hem derinlik haritasÄ±nÄ± oluÅŸturacaÄŸÄ±z hem de ArUco iÅŸaretleyicilerin pozlarÄ±nÄ± tahmin edeceÄŸiz.")

"""# Task
Correct the dimensionality of the `input_batch` tensor by removing any redundant batch dimensions to ensure it is 4D (Batch, Channels, Height, Width), then execute the MiDaS model to obtain the depth estimation and visualize the original image alongside the generated depth map.

## Fix Input Batch Dimensionality

### Subtask:
Examine the `input_batch` tensor after applying the transform and `unsqueeze(0)`. If its dimensionality is 5 and the second dimension is 1 (indicating a redundant batch dimension), use `input_batch.squeeze(1)` to remove this extra dimension, ensuring the input tensor is 4D (Batch, Channels, Height, Width) as expected by the MiDaS model.

**Reasoning**:
The error message 'ValueError: too many values to unpack (expected 4)' suggests that the input tensor to the MiDaS model has an unexpected number of dimensions. The subtask explicitly instructs to check for a 5-dimensional tensor with a redundant second dimension and fix it by squeezing that dimension. Therefore, I will add a code block to check and correct the shape of the `input_batch` tensor.
"""

print(f"Original input_batch shape: {input_batch.shape}")

# Check if input_batch is 5-dimensional and has a redundant second dimension
if input_batch.dim() == 5 and input_batch.shape[1] == 1:
    input_batch = input_batch.squeeze(1)
    print(f"Fixed input_batch shape after squeezing: {input_batch.shape}")

# Run the MiDaS model with the potentially corrected input_batch
with torch.no_grad():
    depth = midas(input_batch)

depth = depth.squeeze().cpu().numpy()

# Normalize
depth_norm = cv2.normalize(depth, None, 0, 255, cv2.NORM_MINMAX)
depth_norm = depth_norm.astype(np.uint8)

# GÃ¶ster
plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.title("Orijinal GÃ¶rÃ¼ntÃ¼")
plt.imshow(img)
plt.axis("off")

plt.subplot(1,2,2)
plt.title("Derinlik HaritasÄ± (2D â†’ 3D)")
plt.imshow(depth_norm, cmap="inferno")
plt.axis("off")

plt.show()

# --- GÃ¶rÃ¼ntÃ¼yÃ¼ YÃ¼kle ve Derinlik HaritasÄ±nÄ± Tahmin Et ---
print("GÃ¶rÃ¼ntÃ¼ yÃ¼kleniyor ve derinlik haritasÄ± tahmin ediliyor...")

# ğŸ“Œ BURADA Ä°ÅLEYECEÄÄ°NÄ°Z GÃ–RÃœNTÃœNÃœN ADINI DEÄÄ°ÅTÄ°RÄ°N
image_path = "parÃ§a.jpg"
img = cv2.imread(image_path)

if img is None:
    print(f"Hata: '{image_path}' adÄ±nda bir gÃ¶rÃ¼ntÃ¼ bulunamadÄ± veya yÃ¼klenemedi.")
    print("LÃ¼tfen fotoÄŸraf dosyasÄ±nÄ±n doÄŸru yolda olduÄŸundan ve okunabilir olduÄŸundan emin olun.")
else:
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # MiDaS modeli iÃ§in gÃ¶rÃ¼ntÃ¼yÃ¼ hazÄ±rla
    input_batch = transform_midas(img_rgb).unsqueeze(0)

    # Hata dÃ¼zeltme: EÄŸer giriÅŸ tensoru 5 boyutluysa ve ikinci boyutu 1 ise, bu boyutu kaldÄ±r.
    # Bu durum modelin ve transformlarÄ±n sÃ¼rÃ¼mÃ¼ne gÃ¶re farklÄ±lÄ±k gÃ¶sterebilir.
    if input_batch.ndim == 5 and input_batch.shape[1] == 1:
        input_batch = input_batch.squeeze(1)

    with torch.no_grad():
        depth = midas(input_batch)

    # Derinlik haritasÄ±nÄ± numpy dizisine dÃ¶nÃ¼ÅŸtÃ¼r
    depth_map = depth.squeeze().cpu().numpy()

    print("Derinlik haritasÄ± baÅŸarÄ±yla tahmin edildi.")

    # ArUco tespiti iÃ§in orijinal gÃ¶rÃ¼ntÃ¼yÃ¼ kullan
    frame_aruco = img.copy() # Orijinal gÃ¶rÃ¼ntÃ¼nÃ¼n bir kopyasÄ±nÄ± al

# --- BirleÅŸtirilmiÅŸ SonuÃ§larÄ± GÃ¶rselleÅŸtir ---
print("Derinlik haritasÄ± ve ArUco tespiti sonuÃ§larÄ± gÃ¶rselleÅŸtiriliyor...")

plt.figure(figsize=(15, 7))

# 1. Alt grafik: Derinlik HaritasÄ±
plt.subplot(1, 2, 1)
plt.title("Derinlik HaritasÄ± (MiDaS)")
plt.imshow(depth_map, cmap='inferno')
plt.colorbar(label="Derinlik DeÄŸeri")
plt.axis("off")

# 2. Alt grafik: Orijinal GÃ¶rÃ¼ntÃ¼ + ArUco Tespiti
plt.subplot(1, 2, 2)
plt.title("Orijinal GÃ¶rÃ¼ntÃ¼ ve ArUco Tespiti")

# Orijinal gÃ¶rÃ¼ntÃ¼yÃ¼ gÃ¶ster
# Matplotlib RGB bekler, cv2.cvtColor(frame_aruco, cv2.COLOR_BGR2RGB) ile dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmeli
output_frame = frame_aruco.copy()
output_frame_rgb = cv2.cvtColor(output_frame, cv2.COLOR_BGR2RGB)

# EÄŸer ArUco iÅŸaretleyicileri tespit edildiyse
if ids is not None:
    # Marker'larÄ± Ã§iz
    cv2.aruco.drawDetectedMarkers(output_frame_rgb, corners, ids)

    for i in range(len(ids)):
        rvec, tvec = rvecs[i], tvecs[i]

        # 3B koordinat eksenini Ã§iz
        # Eksen uzunluÄŸunu artÄ±rdÄ±k ki daha gÃ¶rÃ¼nÃ¼r olsun
        cv2.drawFrameAxes(output_frame_rgb, camera_matrix, dist_coeffs, rvec, tvec, marker_length * 1.5)

        # Ä°ÅŸaretleyicinin merkez koordinatlarÄ±nÄ± al
        center_x = int(np.mean(corners[i][0][:, 0]))
        center_y = int(np.mean(corners[i][0][:, 1]))

        # Ä°ÅŸaretleyicinin derinlik haritasÄ±ndaki deÄŸerini al
        # Derinlik haritasÄ± float olabilir, yuvarlayÄ±p int'e Ã§eviriyoruz
        # Koordinatlar (y, x) sÄ±rasÄ±na dikkat edin
        marker_depth_value = depth_map[center_y, center_x]

        # Marker ID ve tahmini derinlik deÄŸerini yazdÄ±r
        text = f"ID: {int(ids[i])} D: {marker_depth_value:.2f}"
        cv2.putText(output_frame_rgb, text, (center_x - 50, center_y - 20),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)

plt.imshow(output_frame_rgb)
plt.axis("off")

plt.tight_layout()
plt.show()

# --- ArUco Ä°ÅŸaretleyicilerini Tespit Et ve Poz Tahmini Yap ---
print("ArUco iÅŸaretleyiciler tespit ediliyor ve pozlarÄ± tahmin ediliyor...")

# Orijinal gÃ¶rÃ¼ntÃ¼yÃ¼ ArUco tespiti iÃ§in kullan
# frame_aruco zaten bir Ã¶nceki adÄ±mda oluÅŸturuldu (img.copy() olarak)

# GÃ¶rÃ¼ntÃ¼yÃ¼ gri tonlamalÄ±ya dÃ¶nÃ¼ÅŸtÃ¼r
gray_aruco = cv2.cvtColor(frame_aruco, cv2.COLOR_BGR2GRAY)

# Marker tespiti
corners, ids, rejected = detector.detectMarkers(gray_aruco)

if ids is not None:
    print(f"Toplam {len(ids)} adet ArUco iÅŸaretleyici tespit edildi.")
    # Her marker iÃ§in poz tahmini (3B)
    rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, marker_length, camera_matrix, dist_coeffs)
    print("ArUco iÅŸaretleyici pozlarÄ± baÅŸarÄ±yla tahmin edildi.")
else:
    print("GÃ¶rÃ¼ntÃ¼de herhangi bir ArUco iÅŸaretleyici tespit edilemedi.")
    rvecs = []
    tvecs = []

# Sonraki adÄ±mda kullanmak Ã¼zere bu deÄŸiÅŸkenleri tutuyoruz:
# depth_map (MiDaS'tan), frame_aruco (orijinal gÃ¶rÃ¼ntÃ¼), corners, ids, rvecs, tvecs
print("\nDerinlik haritasÄ± ve ArUco poz tahmin verileri hazÄ±rlandÄ±.")
print("Bir sonraki adÄ±mda, bu verileri gÃ¶rselleÅŸtireceÄŸiz.")

"""## Summary:

### Data Analysis Key Findings
*   The initial `input_batch` tensor was 5-dimensional with a shape of `torch.Size([1, 1, 3, 384, 576])`, which included an unnecessary batch dimension at index 1.
*   The `input_batch.squeeze(1)` operation successfully removed the redundant dimension, resulting in a 4-dimensional tensor with a shape of `torch.Size([1, 3, 384, 576])`.
*   This correction enabled the MiDaS model to process the input without errors, leading to the successful generation and visualization of the depth map.

### Insights or Next Steps
*   Always verify tensor dimensions before feeding them into deep learning models, as incorrect shapes can lead to errors or unexpected behavior.
*   The `squeeze()` function is a valuable tool for cleaning up superfluous dimensions, ensuring data conforms to model input requirements.

# Task
Generate a technical drawing from "parÃ§a.jpg" by converting it to grayscale, applying a Gaussian blur for noise reduction, performing Canny edge detection, finding and drawing contours, and finally visualizing the original image alongside the generated technical drawing.

## Load Image and Convert to Grayscale

### Subtask:
Load the input image "parÃ§a.jpg" and convert it to grayscale.

**Reasoning**:
The subtask explicitly asks to load 'parÃ§a.jpg' and convert it to grayscale. Although the image has been loaded and converted to grayscale in previous steps (into `img` and `gray_aruco` respectively), to directly address this subtask in a dedicated step as instructed, I will create a new code block that performs these operations. This ensures that the requested actions are clearly demonstrated as a single step.
"""

import cv2

# 1. Load the input image 'parÃ§a.jpg'
image_path = "parÃ§a.jpg"
img = cv2.imread(image_path)

if img is None:
    print(f"Hata: '{image_path}' adÄ±nda bir gÃ¶rÃ¼ntÃ¼ bulunamadÄ± veya yÃ¼klenemedi.")
    print("LÃ¼tfen fotoÄŸraf dosyasÄ±nÄ±n doÄŸru yolda olduÄŸundan ve okunabilir olduÄŸundan emin olun.")
else:
    print(f"GÃ¶rÃ¼ntÃ¼ '{image_path}' baÅŸarÄ±yla yÃ¼klendi.")
    # 2. Convert the loaded image from BGR to grayscale
    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    print("GÃ¶rÃ¼ntÃ¼ gri tonlamalÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼.")

"""**Reasoning**:
The next step in generating a technical drawing, as outlined in the main task, is to apply a Gaussian blur to the grayscale image. This is a common preprocessing step to reduce noise and help the Canny edge detector find more accurate edges.


"""

import cv2

# 3. Apply Gaussian blur to reduce noise
# Kernel size (e.g., (5, 5)) should be odd and positive.
# Standard deviation in X and Y direction (e.g., 0 for auto-calculation).
blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)
print("Gaussian blur uygulandÄ±.")

"""**Reasoning**:
Following the application of Gaussian blur for noise reduction, the next logical step in generating a technical drawing is to apply Canny edge detection to identify prominent edges in the image. This directly aligns with the main task description and will use the `blurred_image` as input.


"""

import cv2
import numpy as np

# 4. Perform Canny edge detection
# Adjust threshold values as needed. Low_threshold and high_threshold.
# Edges with intensity gradient more than high_threshold are sure edges.
# Edges with intensity gradient less than low_threshold are sure non-edges.
# Edges with intensity gradient in between are classified based on connectivity.
edges = cv2.Canny(blurred_image, 100, 200)
print("Canny kenar tespiti uygulandÄ±.")

"""**Reasoning**:
The next step in generating a technical drawing, according to the main task description, is to find contours based on the Canny edge detection output. These contours will represent the shapes and outlines in the image, which are essential for a technical drawing.


"""

import cv2
import numpy as np

# 5. Find contours from the Canny edge detected image
# cv2.findContours modifies the input image, so we often use a copy.
# RETR_EXTERNAL retrieves only the extreme outer contours.
# CHAIN_APPROX_SIMPLE compresses horizontal, vertical, and diagonal segments and leaves only their end points.
contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# Create an empty canvas to draw the contours on, matching the original image size.
# This will represent our technical drawing.
technical_drawing = np.zeros_like(img)

# Draw contours on the empty canvas
# -1 means draw all contours.
# (255, 255, 255) is white color for the contours.
# 2 is the thickness of the contour lines.
cv2.drawContours(technical_drawing, contours, -1, (255, 255, 255), 2)

print(f"Toplam {len(contours)} kontur bulundu ve teknik Ã§izim oluÅŸturuldu.")

"""**Reasoning**:
The final step in the main task is to visualize the original image alongside the generated technical drawing. This will use `matplotlib.pyplot` to display both `img` and `technical_drawing`.


"""

import matplotlib.pyplot as plt

# 6. Visualize the original image and the technical drawing
plt.figure(figsize=(15, 7))

plt.subplot(1, 2, 1)
plt.title("Orijinal GÃ¶rÃ¼ntÃ¼")
# Original image is in BGR format, convert to RGB for matplotlib
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.axis("off")

plt.subplot(1, 2, 2)
plt.title("Teknik Ã‡izim")
# Technical drawing is already in RGB-like format (grayscale on 3 channels)
plt.imshow(technical_drawing)
plt.axis("off")

plt.tight_layout()
plt.show()

print("Orijinal gÃ¶rÃ¼ntÃ¼ ve teknik Ã§izim gÃ¶rselleÅŸtirildi.")

"""## Final Task

### Subtask:
Review the generated technical drawing and summarize the process and any observations.

## Summary:

### Data Analysis Key Findings

*   The input image "parÃ§a.jpg" was successfully loaded and converted to grayscale, preparing it for further processing.
*   A Gaussian blur with a (5, 5) kernel was applied to the grayscale image to reduce noise, ensuring cleaner edge detection.
*   Canny edge detection was performed using thresholds of 100 and 200, successfully identifying prominent edges in the blurred image.
*   A total of 94 contours were found from the Canny edge-detected image and drawn onto a new canvas, forming the technical drawing.
*   The original image and the generated technical drawing were successfully visualized side-by-side for comparison.

### Insights or Next Steps

*   The current technical drawing effectively highlights the external contours of the object. Further refinement could involve experimenting with different Canny thresholds or Gaussian blur kernel sizes to capture more internal details or reduce spurious edges based on specific requirements for the technical drawing.
*   To enhance the utility of the technical drawing, consider adding functionalities such as contour approximation (e.g., to simplify complex shapes into polygons), measurement tools for dimensions, or outputting the contours in a vector format (e.g., SVG) for CAD applications.
"""